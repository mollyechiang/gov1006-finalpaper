---
title: "Final Paper"
author: "Chelsea Marlborough"
date: "4/15/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(foreign)
library(lmtest)
library(sandwich)
library(Matching)
library(ebal)
library(memisc)
library(ggplot2)
library(sp)
library(maptools) 
library(rgdal) 
library(rgeos)
library(AER)
library(plyr)
library(scales) 
library(RColorBrewer)

options(digits=10)
options(scipen=10)
set.seed(02139)

```

```{r reading in data, include = FALSE}

divisions <- read.csv("replication_file.csv", stringsAsFactors=FALSE, na.strings=c("NA", ""),  strip.white = TRUE)

divisions$poll_id_07 <- as.factor(divisions$poll_id_07) #several variables need to be factors to ensure the functions run properly
divisions$master_id <- as.factor(divisions$master_id)
divisions$poll_id_03 <- as.factor(divisions$poll_id_03)
divisions$fed_id <- as.factor(divisions$fed_id)

```

```{r demeanor function, include=FALSE}

 demeaner <- function(yx, T, group, w=NULL){
    conds <- length(levels(T))
    n <- length(T)
    Td = as.data.frame(model.matrix(~T-1,model.frame(~T-1),contrasts=FALSE)[1:n,1:conds])
    colnames(Td)<- paste("Y", levels(T)[1:conds], sep="") #puts a Y in front of the year/time variable so they are character strings
    
    yx <- cbind(yx, Td)
    
    yx2 <- matrix(NA, nrow=nrow(yx), ncol=ncol(yx)) # this is a big empty matrix we will fill
    group <- droplevels(group)
    
    for (c in levels(group)){
      yx.c <- as.matrix(yx[group==c,],ncol=ncol(yx))
      if (is.null(w)){
        yx2[group==c,] <- yx.c - matrix(rep(colMeans(yx.c),times=nrow(yx.c)),ncol=ncol(yx.c),byrow=TRUE)
      } else {
        yx2[group==c,] <- yx.c - matrix(rep(apply(yx.c,2,weighted.mean,w=weights),times=nrow(yx.c)),ncol=ncol(yx.c),byrow=TRUE)
      }
    }
    
    colnames(yx2) <- colnames(yx)
    
    rm(yx)
    yx2=as.data.frame(yx2)
    return(yx2)
  }

```

```{r vcov cluster function with demean, include=FALSE}

vcovCluster_demean <- function(model, cluster, first)
  {
    require(sandwich)
    require(lmtest)
    cluster <- droplevels(cluster)
    if(nrow(model.matrix(model))!=length(cluster)){
      stop("check your data: cluster variable has different N than model")
    }
    M <- length(unique(cluster))
    N <- length(cluster)           
    K <- model$rank   
    if(M<50){
      warning("Fewer than 50 clusters, variances may be unreliable (could try block bootstrap instead).")
    }
    dfc <- (M/(M - 1)) * ((N - 1)/(N - K - first)) #NOTE: need to change this 6186 if the clusters is different
    uj  <- apply(estfun(model), 2, function(x) tapply(x, cluster, sum));
    rcse.cov <- dfc * sandwich(model, meat = crossprod(uj)/N)
    return(rcse.cov)
  }

```

```{r vcov cluster function, include=FALSE}

vcovCluster <- function(model, cluster)
  {
    require(sandwich)
    require(lmtest)
    if(nrow(model.matrix(model))!=length(cluster)){
      stop("check your data: cluster variable has different N than model")
    }
    M <- length(unique(cluster))
    N <- length(cluster)           
    K <- model$rank   
    if(M<50){
      warning("Fewer than 50 clusters, variances may be unreliable (could try block bootstrap instead).")
    }
    dfc <- (M/(M - 1)) * ((N - 1)/(N - K )) 
    uj  <- apply(estfun(model), 2, function(x) tapply(x, cluster, sum));
    rcse.cov <- dfc * sandwich(model, meat = crossprod(uj)/N)
    return(rcse.cov)
  }

```

```{r summarize function, include=FALSE}

summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {
    require(plyr)
    
    # New version of length which can handle NA's: if na.rm==T, don't count them
    length2 <- function (x, na.rm=FALSE) {
      if (na.rm) sum(!is.na(x))
      else       length(x)
    }
    
    # This does the summary. For each group's data frame, return a vector with
    # N, mean, and sd
    datac <- ddply(data, groupvars, .drop=.drop,
                   .fun = function(xx, col) {
                     c(N    = length2(xx[[col]], na.rm=na.rm),
                       mean = mean   (xx[[col]], na.rm=na.rm),
                       sd   = sd     (xx[[col]], na.rm=na.rm)
                     )
                   },
                   measurevar
    )
    
    # Rename the "mean" column    
    datac <- rename(datac, c("mean" = measurevar))
    
    datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
    
    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval: 
    # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult
    
    return(datac)
  }

```

```{r missing data, include = FALSE}

dt <- divisions
  
  # Shows the amount 
  length(which(is.na(dt$log_pop))) / nrow(dt) #1%
  length(which(is.na(dt$log_pop_denc))) / nrow(dt) #1%
  length(which(is.na(dt$log_median_inc))) / nrow(dt) #4%
  length(which(is.na(dt$avg_home_val_log))) / nrow(dt) #3%
  length(which(is.na(dt$unemploy_rate))) / nrow(dt) #3%
  length(which(is.na(dt$p_uni_degree))) / nrow(dt) #2%
  length(which(is.na(dt$p_immigrant))) / nrow(dt) #2%
  length(which(is.na(dt$p_housing_own))) / nrow(dt) #2%
  
  #subset the data by year
  d2007 <- dt[which(dt$year==2007),]
  d2011 <- dt[which(dt$year==2011),]
  d2003 <- dt[which(dt$year==2003),]
  
  # Eliminate missing data by setting missing values equal to the mean for each year and variable
  d2007$log_pop_denc[which(is.na(d2007$log_pop_denc))] <- mean(d2007$log_pop_denc, na.rm=T)
  d2007$log_pop[which(is.na(d2007$log_pop))] <- mean(d2007$log_pop, na.rm=T)
  d2007$log_median_inc[which(is.na(d2007$log_median_inc))] <- mean(d2007$log_median_inc, na.rm=T)
  d2007$avg_home_val_log[which(is.na(d2007$avg_home_val_log))] <- mean(d2007$avg_home_val_log, na.rm=T)
  d2007$avg_home_val[which(is.na(d2007$avg_home_val))] <- mean(d2007$avg_home_val, na.rm=T)
  d2007$unemploy_rate[which(is.na(d2007$unemploy_rate))] <- mean(d2007$unemploy_rate, na.rm=T)
  d2007$p_uni_degree[which(is.na(d2007$p_uni_degree))] <- mean(d2007$p_uni_degree, na.rm=T)
  d2007$p_immigrant[which(is.na(d2007$p_immigrant))] <- mean(d2007$p_immigrant, na.rm=T)
  d2007$p_housing_own[which(is.na(d2007$p_housing_own))] <- mean(d2007$p_housing_own, na.rm=T)
  
  d2011$log_pop_denc[which(is.na(d2011$log_pop_denc))] <- mean(d2011$log_pop_denc, na.rm=T)
  d2011$log_pop[which(is.na(d2011$log_pop))] <- mean(d2011$log_pop, na.rm=T)
  d2011$log_median_inc[which(is.na(d2011$log_median_inc))] <- mean(d2011$log_median_inc, na.rm=T)
  d2011$avg_home_val_log[which(is.na(d2011$avg_home_val_log))] <- mean(d2011$avg_home_val_log, na.rm=T)
  d2011$avg_home_val[which(is.na(d2011$avg_home_val))] <- mean(d2011$avg_home_val, na.rm=T)
  d2011$unemploy_rate[which(is.na(d2011$unemploy_rate))] <- mean(d2011$unemploy_rate, na.rm=T)
  d2011$p_uni_degree[which(is.na(d2011$p_uni_degree))] <- mean(d2011$p_uni_degree, na.rm=T)
  d2011$p_immigrant[which(is.na(d2011$p_immigrant))] <- mean(d2011$p_immigrant, na.rm=T)
  d2011$p_housing_own[which(is.na(d2011$p_housing_own))] <- mean(d2011$p_housing_own, na.rm=T)
  
  d2003$log_pop_denc[which(is.na(d2003$log_pop_denc))] <- mean(d2003$log_pop_denc, na.rm=T)
  d2003$log_pop[which(is.na(d2003$log_pop))] <- mean(d2003$log_pop, na.rm=T)
  d2003$log_median_inc[which(is.na(d2003$log_median_inc))] <- mean(d2003$log_median_inc, na.rm=T)
  d2003$avg_home_val_log[which(is.na(d2003$avg_home_val_log))] <- mean(d2003$avg_home_val_log, na.rm=T)
  d2003$avg_home_val[which(is.na(d2003$avg_home_val))] <- mean(d2003$avg_home_val, na.rm=T)
  d2003$unemploy_rate[which(is.na(d2003$unemploy_rate))] <- mean(d2003$unemploy_rate, na.rm=T)
  d2003$p_uni_degree[which(is.na(d2003$p_uni_degree))] <- mean(d2003$p_uni_degree, na.rm=T)
  d2003$p_immigrant[which(is.na(d2003$p_immigrant))] <- mean(d2003$p_immigrant, na.rm=T)
  d2003$p_housing_own[which(is.na(d2003$p_housing_own))] <- mean(d2003$p_housing_own, na.rm=T)
  
  # put the data back together
  dt <- rbind(d2003,d2007,d2011)
  
  #make square terms for each variable - used in entropy balancing
  dt$log_pop_sq <- (dt$log_pop)^2
  dt$log_pop_denc_sq <- (dt$log_pop_denc)^2
  dt$log_median_inc_sq <- (dt$log_median_inc)^2
  dt$avg_home_val_log_sq <- (dt$avg_home_val_log)^2
  dt$unemploy_rate_sq <- (dt$unemploy_rate)^2
  dt$p_uni_degree_sq <- (dt$p_uni_degree)^2
  dt$p_immigrant_sq <- (dt$p_immigrant)^2
  dt$p_housing_own_sq <- (dt$p_housing_own)^2
  
  #subset
  d2007 <- dt[which(dt$year==2007),]
  d2011 <- dt[which(dt$year==2011),]
  d2003 <- dt[which(dt$year==2003),]
  
  # overwrite the initial data file with data without missing values
  divisions <- dt
  rm(dt)

```

```{r data construction, include=FALSE}

div_rural <- divisions[which(divisions$pop_denc <= 400 & divisions$year==2007),] # Cut out divisions with population density greater than 400 people per km^2 in 2007. N=3169.
  
  # Need to find the matching 2003 and 2011 divisions to complete the panel.
  a <- rbind(div_rural, d2011)
  dup_id <- which(duplicated(a$master_id)==T)
  dup_id_2 <- which(duplicated(a$master_id, fromLast = TRUE)==T)
  keep <- c(dup_id,dup_id_2)
  a <- a[keep,]
  length(which(a$year==2007)) == length(which(a$year==2011)) # This is a check - you want this to say TRUE.
  b <- rbind(d2003, div_rural)
  dup_id <- which(duplicated(b$master_id)==T)
  dup_id_2 <- which(duplicated(b$master_id, fromLast = TRUE)==T)
  keep <- c(dup_id,dup_id_2)
  b <- b[keep,]
  length(which(b$year==2007)) == length(which(b$year==2003)) # This is a check - you want this to say TRUE.
  div_rural <- rbind(a, b[which(b$year==2003),])
  rm(a, b, dup_id, dup_id_2, keep)
  
  div_rural$master_id <- droplevels(div_rural$master_id) #Important before running analysis because master_id is a factor.
  
  #Check to see all treated units are still in this rural dataset:
  propsr <- divisions[which(divisions$prop==1),] 
  opsr <- divisions[which(divisions$op==1),]
  length(unique(propsr$master_id)) #184
  length(unique(opsr$master_id)) #52
  rm(propsr, opsr)
  
  # Create weights for balanced models with entropy balancing:
  # Proposed variable
  N <- 6186
  #Will use X and then X^2 to balance for each variable
  X_bal <- d2003[,c("log_pop_denc", "log_pop", "log_median_inc", "avg_home_val_log", "unemploy_rate", "p_uni_degree", "p_immigrant", "p_housing_own", "log_pop_denc_sq", "log_pop_sq", "log_median_inc_sq", "avg_home_val_log_sq", "unemploy_rate_sq", "p_uni_degree_sq", "p_immigrant_sq", "p_housing_own_sq")] #variables to balance on, per the paper.
  ebalout <- ebalance(Treatment=d2003$treat_p, X=X_bal)
  
  #That only gives weights for controls; I'd like an N-dim vector with all weights:
  ebalw <- replicate(N, 1) #for every treated unit, give the weight of 1.
  ebalw[d2003$treat_p==0]=ebalout$w #for every control unit, give the weight from the model.
  
  #Add the proposed variable weights to the dataset
  d2007$weights_p <- ebalw
  d2003$weights_p <- ebalw
  d2011$weights_p <- ebalw
  
  divisions <- rbind(d2007, d2003, d2011)
  rm(ebalout, ebalw, N, X_bal)
  
  # Operational variable
  N <- 6186
  X_bal <- d2003[,c("log_pop_denc", "log_pop", "log_median_inc", "avg_home_val_log" ,"unemploy_rate" , "p_uni_degree", "p_immigrant", "p_housing_own", "log_pop_denc_sq", "log_pop_sq", "log_median_inc_sq", "avg_home_val_log_sq" ,"unemploy_rate_sq" , "p_uni_degree_sq", "p_immigrant_sq", "p_housing_own_sq")] #variables to balance on, per the paper.
  ebalout <- ebalance(Treatment=d2003$treat_o, X=X_bal)
  
  #That only gives weights for controls; I'd like an N-dim vector with all weights:
  ebalw <- replicate(N, 1) #for every treated unit, give the weight of 1.
  ebalw[d2003$treat_o==0]=ebalout$w #for every control unit, give the weight from the model.
  
  #weights are ebalw... 
  d2007$weights_o <- ebalw
  d2003$weights_o <- ebalw
  d2011$weights_o <- ebalw
  
  divisions <- rbind(d2007, d2003, d2011)
  rm(ebalout, ebalw, N, X_bal)

```

```{r instrument, include=FALSE}

d2011_d <- d2011[which(d2011$avg_pwr > 0),] # Only keeps units with windspeed data greater than 0.
d2007_d <- d2007[which(d2007$prop_3km != 1),] # Removes units already treated in 2007 (within 3 km of turbine).
ivpanel <- rbind(d2007_d, d2011_d) # IV panel does not include 2003 data. It only looks at changes between 2007 and 2011. However, 2003 data is used for robustness checks in SI.
  
  # Make the panel equally balanced by cutting out units that were removed in one year but not the others.
  a <- ivpanel 
  dup_id <- which(duplicated(a$master_id)==T)
  dup_id_2 <- which(duplicated(a$master_id, fromLast = TRUE)==T)
  keep <- c(dup_id,dup_id_2)
  a <- a[keep,]
  length(which(a$year==2007)) == length(which(a$year==2011)) # you want this to say TRUE.
  rm(dup_id, dup_id_2, keep)
  b <- a[which(a$year==2007),]
  b <- rbind(b, d2003)
  dup_id <- which(duplicated(b$master_id)==T)
  dup_id_2 <- which(duplicated(b$master_id, fromLast = TRUE)==T)
  keep <- c(dup_id,dup_id_2)
  b <- b[keep,]
  length(which(b$year==2007)) == length(which(b$year==2003)) # you want this to say TRUE.
  a <- a[which(a$year==2011),]
  ivpanel <- rbind(a, b)
  rm(a, b, keep, dup_id, dup_id_2, d2011_d, d2007_d, d2003, d2007, d2011)
  
  ivd <- ivpanel[which(ivpanel$year==2011),] 
  iv07 <- ivpanel[which(ivpanel$year==2007),]

  sum(ivd$prop_3km) #354 - 2011 treated units, within 3 km of a proposed turbine - we will find matched control units for these.
  
  ivd$chng_lib <- ivd$perc_lib-iv07$perc_lib # new DV for instrumental variable cross section -- see Table 2.

  # Create pre-treatment average home value data in IV data
  ivd$avg_home_val_log_07 <- log(iv07$avg_home_val)
  ivd$avg_home_val_log_07[which(is.na(ivd$avg_home_val_log_07))] <- mean(ivd$avg_home_val_log_07, na.rm=T)
  
  # Create other variables necessary for IV model
  ivd$avg_pwr_log <- log(ivd$avg_pwr)
  ivd$mindistlake_log <- log(1+ivd$mindistlake)
  ivd$mindistlake_sq <- ivd$mindistlake * ivd$mindistlake
  ivd$long_sq <- ivd$longitude * ivd$longitude
  ivd$lat_sq <- ivd$latitude * ivd$latitude
  ivd$long_lat <- ivd$latitude * ivd$longitude
  
  # Find 354 matched pairs for instrumental variable model. Match based of four variables reported in paper. Use 2011 'ivd' dataset created above.
  match.covars <- ivd[,c("avg_home_val_log_07", "p_uni_degree", "log_median_inc", "log_pop_denc")]
  sum(ivd$prop_3km==1) #354 - number of treated units
  
  match <- Match(Y=ivd$chng_lib, Tr=ivd$prop_3km, X=match.covars, estimand="ATT", M=1, exact=c(F,F,F,F), replace=FALSE) # Finding 1 controls for each unit and not allowing reuse. Matches do not have to be exact.
  
  matchobj_tr <- ivd[match$index.treated,] # these are the treated units
  matchobj_ct <- ivd[match$index.control,] # these are the control units
  matchobj <- rbind(matchobj_tr, matchobj_ct) # matched dataset, for instrument analysis
  
  rm(match.covars, ivd, iv07, ivpanel, match)

```

```{r table 1}

yx_data <- divisions[,c("perc_lib","prop")]
  yx_diffed <- demeaner(yx=yx_data, T=as.factor(divisions$year), group=divisions$master_id)
  mod_1 <- lm(perc_lib ~ prop + Y2003 + Y2007, data=yx_diffed)
  round(coeftest(mod_1, vcov=vcovCluster_demean(mod_1, cluster=divisions$master_id, first=nrow(divisions)/3)),3)
  
  # Column 1 (All Precincts), Section 2 (Turbine Operational)
  # Using panel demeaning function 
  yx_data <- divisions[,c("perc_lib","op")]
  yx_diffed <- demeaner(yx=yx_data, T=as.factor(divisions$year), group=divisions$master_id)
  mod_2 <- lm(perc_lib ~ op + Y2003 + Y2007, data=yx_diffed)
  round(coeftest(mod_2, vcov=vcovCluster_demean(mod_2, cluster=divisions$master_id, first=nrow(divisions)/3)),3) 
  
  # Column 2 (All Precincts with Controls), Section 1 (Turbine Proposal)
  divisions <- droplevels(divisions)
  yx_data <- divisions[,c("perc_lib", "prop", "p_uni_degree", "log_pop_denc", "unemploy_rate", "log_median_inc", "p_immigrant")] 
  yx_diffed <- demeaner(yx=yx_data, T=as.factor(divisions$year), group=divisions$master_id) # group needs to be a factor as well
  mod_3 <- lm(perc_lib ~ prop + Y2003 + Y2007 + p_uni_degree + log_pop_denc + unemploy_rate + log_median_inc + p_immigrant, data=yx_diffed)
  round(coeftest(mod_3, vcov=vcovCluster_demean(mod_3, cluster=divisions$master_id, first=nrow(divisions)/3)),3)
  
  # Column 2 (All Precincts with Controls), Section 2 (Turbine Operational)
  divisions <- droplevels(divisions)
  yx_data <- divisions[,c("perc_lib", "op", "p_uni_degree", "log_pop_denc", "unemploy_rate", "log_median_inc", "p_immigrant")] 
  yx_diffed <- demeaner(yx=yx_data, T=as.factor(divisions$year), group=divisions$master_id) # group needs to be a factor as well
  mod_4 <- lm(perc_lib ~ op + Y2003 + Y2007 + p_uni_degree + log_pop_denc + unemploy_rate + log_median_inc + p_immigrant, data=yx_diffed)
  round(coeftest(mod_4, vcov=vcovCluster_demean(mod_4, cluster=divisions$master_id, first=nrow(divisions)/3)),3)
  
  
  # Column 3 (Rural Precincts), Section 1 (Turbine Proposal)
  div_rural <- droplevels(div_rural) #Note: you need to have created the rural subset in Data Construction section above.
  yx_data <- div_rural[,c("perc_lib","prop")]
  yx_diffed <- demeaner(yx=yx_data, T=as.factor(div_rural$year), group=div_rural$master_id)
  mod_5 <- lm(perc_lib ~ prop + Y2003 + Y2007, data=yx_diffed)
  round(coeftest(mod_5, vcov=vcovCluster_demean(mod_5, cluster=div_rural$master_id, first=nrow(div_rural)/3)),3) 
  
  # Column 3 (Rural Precincts), Section 2 (Turbine Operational)
  div_rural <- droplevels(div_rural)
  yx_data <- div_rural[,c("perc_lib","op")]
  yx_diffed <- demeaner(yx=yx_data, T=as.factor(div_rural$year), group=div_rural$master_id) # change dataset
  mod_6 <- lm(perc_lib ~ op + Y2003 + Y2007, data=yx_diffed) #change treatment variable
  round(coeftest(mod_6, vcov=vcovCluster_demean(mod_6, cluster=div_rural$master_id, first=nrow(div_rural)/3)),3) 
  
  
  # Column 4 (Rural Precincts with Controls), Section 1 (Turbine Proposal)
  div_rural <- droplevels(div_rural)
  yx_data <- div_rural[,c("perc_lib", "prop", "p_uni_degree", "log_pop_denc", "unemploy_rate", "log_median_inc", "p_immigrant")] 
  yx_diffed <- demeaner(yx=yx_data, T=as.factor(div_rural$year), group=div_rural$master_id)
  mod_7 <- lm(perc_lib ~ prop + Y2003 + Y2007 + p_uni_degree + log_pop_denc + unemploy_rate + log_median_inc + p_immigrant, data=yx_diffed)
  round(coeftest(mod_7, vcov=vcovCluster_demean(mod_7, cluster=div_rural$master_id, first=nrow(div_rural)/3)),3)
  
  # Column 4 (Rural Precincts with Controls), Section 2 (Turbine Operational)
  div_rural <- droplevels(div_rural)
  yx_data <- div_rural[,c("perc_lib", "op", "p_uni_degree", "log_pop_denc", "unemploy_rate", "log_median_inc", "p_immigrant")] 
  yx_diffed <- demeaner(yx=yx_data, T=as.factor(div_rural$year), group=div_rural$master_id)
  mod_8 <- lm(perc_lib ~ op + Y2003 + Y2007 + p_uni_degree + log_pop_denc + unemploy_rate + log_median_inc + p_immigrant, data=yx_diffed)
  round(coeftest(mod_8, vcov=vcovCluster_demean(mod_8, cluster=div_rural$master_id, first=nrow(div_rural)/3)),3)
  
  
  # Column 5 (Balanced Precincts), Section 1 (Turbine Proposal)
  yx_data <- divisions[,c("perc_lib","prop")]
  yx_diffed <- demeaner(yx=yx_data, T=as.factor(divisions$year), group=divisions$master_id)
  mod_9 <- lm(perc_lib ~ prop + Y2003 + Y2007, data=yx_diffed, weights=divisions$weights_p) # add in weights
  round(coeftest(mod_9, vcov=vcovCluster_demean(mod_9, cluster=divisions$master_id, first=nrow(divisions)/3)),3)
  
  # Column 5 (Balanced Precincts), Section 2 (Turbine Operational)
  yx_data <- divisions[,c("perc_lib","op")]
  yx_diffed <- demeaner(yx=yx_data, T=as.factor(divisions$year), group=divisions$master_id)
  mod_10 <- lm(perc_lib ~ op + Y2003 + Y2007, data=yx_diffed, weights=divisions$weights_o) # add in weights
  round(coeftest(mod_10, vcov=vcovCluster_demean(mod_10, cluster=divisions$master_id, first=nrow(divisions)/3)),3)
  
  
  # Column 6 (Balanced Precincts), Section 1 (Turbine Proposal)
  yx_data <- divisions[,c("perc_lib", "prop", "p_uni_degree", "log_pop_denc", "unemploy_rate", "log_median_inc", "p_immigrant")]
  yx_diffed <- demeaner(yx=yx_data, T=as.factor(divisions$year), group=divisions$master_id)
  mod_11 <- lm(perc_lib ~ prop + Y2003 + Y2007 + p_uni_degree + log_pop_denc + unemploy_rate + log_median_inc + p_immigrant, data=yx_diffed, weights=divisions$weights_p) # add in weights
  round(coeftest(mod_11, vcov=vcovCluster_demean(mod_11, cluster=divisions$master_id, first=nrow(divisions)/3)),3)
  
  # Column 6 (Balanced Precincts), Section 2 (Turbine Operational)
  yx_data <- divisions[,c("perc_lib", "op", "p_uni_degree", "log_pop_denc", "unemploy_rate", "log_median_inc", "p_immigrant")]
  yx_diffed <- demeaner(yx=yx_data, T=as.factor(divisions$year), group=divisions$master_id)
  mod_12 <- lm(perc_lib ~ op + Y2003 + Y2007 + p_uni_degree + log_pop_denc + unemploy_rate + log_median_inc + p_immigrant, data=yx_diffed, weights=divisions$weights_o) # add in weights
  round(coeftest(mod_12, vcov=vcovCluster_demean(mod_12, cluster=divisions$master_id, first=nrow(divisions)/3)),3)
  
  rm(mod_1, mod_2, mod_3, mod_4, mod_5, mod_6, mod_7, mod_8, mod_9, mod_10, mod_11, mod_12, yx_data, yx_diffed)


```

```{r table 2}

first <- lm(prop_3km ~ avg_pwr_log + mindistlake + mindistlake_sq + longitude + latitude + long_sq + lat_sq + long_lat + as.factor(ed_id), data=matchobj)
  summary(first)
  
  # F-statistic on instrument 
mod1 <- lm(prop_3km ~ longitude + latitude + long_sq + lat_sq + mindistlake + mindistlake_sq + long_lat + as.factor(ed_id), data=matchobj) # Run one model without the instrument.
  mod2 <- lm(prop_3km ~ avg_pwr_log + longitude + latitude + long_sq + lat_sq + mindistlake + mindistlake_sq + long_lat + as.factor(ed_id), data=matchobj) # Run a second model with the instrument.
  waldtest(mod2, mod1) #Compare the two using a wald test. F-statistic = 68.
  
  # Column 2, Second Stage
summary(ivreg(chng_lib ~ prop_3km + mindistlake + mindistlake_sq + longitude + long_sq + latitude + lat_sq + long_lat + as.factor(ed_id) | avg_pwr_log + mindistlake + mindistlake_sq + longitude + long_sq + latitude + lat_sq + long_lat + as.factor(ed_id), data = matchobj))
  
rm(first, mod1, mod2)


```

```{r table 3}

yx_data <- divisions[,c("perc_turnout","prop")]
  yx_diffed <- demeaner(yx=yx_data, T=as.factor(divisions$year), group=divisions$master_id)
  mod_1 <- lm(perc_turnout ~ prop + Y2003 + Y2007, data=yx_diffed)
  round(coeftest(mod_1, vcov=vcovCluster_demean(mod_1, cluster=divisions$master_id, first=nrow(divisions)/3)),3) 
  
  # Column 2, Proposal in Precinct effect on Turnout
  yx_data <- divisions[,c("perc_turnout","prop_3km")]
  yx_diffed <- demeaner(yx=yx_data, T=as.factor(divisions$year), group=divisions$master_id)
  mod_2 <- lm(perc_turnout ~ prop_3km + Y2003 + Y2007, data=yx_diffed)
  round(coeftest(mod_2, vcov=vcovCluster_demean(mod_2, cluster=divisions$master_id, first=nrow(divisions)/3)),3) 
  
  # Column 3, Operational in Precinct effect on Turnout
  yx_data <- divisions[,c("perc_turnout","op")]
  yx_diffed <- demeaner(yx=yx_data, T=as.factor(divisions$year), group=divisions$master_id)
  mod_3 <- lm(perc_turnout ~ op + Y2003 + Y2007, data=yx_diffed)
  round(coeftest(mod_3, vcov=vcovCluster_demean(mod_3, cluster=divisions$master_id, first=nrow(divisions)/3)),3) 
  
  # Column 4, Operational in Precinct effect on Turnout
  yx_data <- divisions[,c("perc_turnout","op_3km")]
  yx_diffed <- demeaner(yx=yx_data, T=as.factor(divisions$year), group=divisions$master_id)
  mod_4 <- lm(perc_turnout ~ op_3km + Y2003 + Y2007, data=yx_diffed)
  round(coeftest(mod_4, vcov=vcovCluster_demean(mod_4, cluster=divisions$master_id, first=nrow(divisions)/3)),3) 
  
rm(mod_1, mod_2, mod_3, mod_4, yx_data, yx_diffed)

```

