---
title: "Final Paper"
author: "Chelsea Marlborough"
date: "4/15/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(foreign)
library(lmtest)
library(sandwich)
library(Matching)
library(ebal)
library(memisc)
library(ggplot2)
library(sp)
library(maptools) 
library(rgdal) 
library(rgeos)
library(AER)
library(plyr)
library(scales) 
library(RColorBrewer)

options(digits=10)
options(scipen=10)
set.seed(02139)

```

```{r reading in data, include = FALSE}

divisions <- read.csv("replication_file.csv", stringsAsFactors=FALSE, na.strings=c("NA", ""),  strip.white = TRUE)

divisions$poll_id_07 <- as.factor(divisions$poll_id_07) #several variables need to be factors to ensure the functions run properly
divisions$master_id <- as.factor(divisions$master_id)
divisions$poll_id_03 <- as.factor(divisions$poll_id_03)
divisions$fed_id <- as.factor(divisions$fed_id)

```

```{r demeanor function, include=FALSE}

 demeaner <- function(yx, T, group, w=NULL){
    conds <- length(levels(T))
    n <- length(T)
    Td = as.data.frame(model.matrix(~T-1,model.frame(~T-1),contrasts=FALSE)[1:n,1:conds])
    colnames(Td)<- paste("Y", levels(T)[1:conds], sep="") #puts a Y in front of the year/time variable so they are character strings
    
    yx <- cbind(yx, Td)
    
    yx2 <- matrix(NA, nrow=nrow(yx), ncol=ncol(yx)) # this is a big empty matrix we will fill
    group <- droplevels(group)
    
    for (c in levels(group)){
      yx.c <- as.matrix(yx[group==c,],ncol=ncol(yx))
      if (is.null(w)){
        yx2[group==c,] <- yx.c - matrix(rep(colMeans(yx.c),times=nrow(yx.c)),ncol=ncol(yx.c),byrow=TRUE)
      } else {
        yx2[group==c,] <- yx.c - matrix(rep(apply(yx.c,2,weighted.mean,w=weights),times=nrow(yx.c)),ncol=ncol(yx.c),byrow=TRUE)
      }
    }
    
    colnames(yx2) <- colnames(yx)
    
    rm(yx)
    yx2=as.data.frame(yx2)
    return(yx2)
  }

```

```{r vcov cluster function with demean, include=FALSE}

vcovCluster_demean <- function(model, cluster, first)
  {
    require(sandwich)
    require(lmtest)
    cluster <- droplevels(cluster)
    if(nrow(model.matrix(model))!=length(cluster)){
      stop("check your data: cluster variable has different N than model")
    }
    M <- length(unique(cluster))
    N <- length(cluster)           
    K <- model$rank   
    if(M<50){
      warning("Fewer than 50 clusters, variances may be unreliable (could try block bootstrap instead).")
    }
    dfc <- (M/(M - 1)) * ((N - 1)/(N - K - first)) #NOTE: need to change this 6186 if the clusters is different
    uj  <- apply(estfun(model), 2, function(x) tapply(x, cluster, sum));
    rcse.cov <- dfc * sandwich(model, meat = crossprod(uj)/N)
    return(rcse.cov)
  }

```

```{r vcov cluster function, include=FALSE}

vcovCluster <- function(model, cluster)
  {
    require(sandwich)
    require(lmtest)
    if(nrow(model.matrix(model))!=length(cluster)){
      stop("check your data: cluster variable has different N than model")
    }
    M <- length(unique(cluster))
    N <- length(cluster)           
    K <- model$rank   
    if(M<50){
      warning("Fewer than 50 clusters, variances may be unreliable (could try block bootstrap instead).")
    }
    dfc <- (M/(M - 1)) * ((N - 1)/(N - K )) 
    uj  <- apply(estfun(model), 2, function(x) tapply(x, cluster, sum));
    rcse.cov <- dfc * sandwich(model, meat = crossprod(uj)/N)
    return(rcse.cov)
  }

```

```{r summarize function, include=FALSE}

summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {
    require(plyr)
    
    # New version of length which can handle NA's: if na.rm==T, don't count them
    length2 <- function (x, na.rm=FALSE) {
      if (na.rm) sum(!is.na(x))
      else       length(x)
    }
    
    # This does the summary. For each group's data frame, return a vector with
    # N, mean, and sd
    datac <- ddply(data, groupvars, .drop=.drop,
                   .fun = function(xx, col) {
                     c(N    = length2(xx[[col]], na.rm=na.rm),
                       mean = mean   (xx[[col]], na.rm=na.rm),
                       sd   = sd     (xx[[col]], na.rm=na.rm)
                     )
                   },
                   measurevar
    )
    
    # Rename the "mean" column    
    datac <- rename(datac, c("mean" = measurevar))
    
    datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
    
    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval: 
    # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult
    
    return(datac)
  }

```

```{r missing data, include = FALSE}

dt <- divisions
  
  # Shows the amount 
  length(which(is.na(dt$log_pop))) / nrow(dt) #1%
  length(which(is.na(dt$log_pop_denc))) / nrow(dt) #1%
  length(which(is.na(dt$log_median_inc))) / nrow(dt) #4%
  length(which(is.na(dt$avg_home_val_log))) / nrow(dt) #3%
  length(which(is.na(dt$unemploy_rate))) / nrow(dt) #3%
  length(which(is.na(dt$p_uni_degree))) / nrow(dt) #2%
  length(which(is.na(dt$p_immigrant))) / nrow(dt) #2%
  length(which(is.na(dt$p_housing_own))) / nrow(dt) #2%
  
  #subset the data by year
  d2007 <- dt[which(dt$year==2007),]
  d2011 <- dt[which(dt$year==2011),]
  d2003 <- dt[which(dt$year==2003),]
  
  # Eliminate missing data by setting missing values equal to the mean for each year and variable
  d2007$log_pop_denc[which(is.na(d2007$log_pop_denc))] <- mean(d2007$log_pop_denc, na.rm=T)
  d2007$log_pop[which(is.na(d2007$log_pop))] <- mean(d2007$log_pop, na.rm=T)
  d2007$log_median_inc[which(is.na(d2007$log_median_inc))] <- mean(d2007$log_median_inc, na.rm=T)
  d2007$avg_home_val_log[which(is.na(d2007$avg_home_val_log))] <- mean(d2007$avg_home_val_log, na.rm=T)
  d2007$avg_home_val[which(is.na(d2007$avg_home_val))] <- mean(d2007$avg_home_val, na.rm=T)
  d2007$unemploy_rate[which(is.na(d2007$unemploy_rate))] <- mean(d2007$unemploy_rate, na.rm=T)
  d2007$p_uni_degree[which(is.na(d2007$p_uni_degree))] <- mean(d2007$p_uni_degree, na.rm=T)
  d2007$p_immigrant[which(is.na(d2007$p_immigrant))] <- mean(d2007$p_immigrant, na.rm=T)
  d2007$p_housing_own[which(is.na(d2007$p_housing_own))] <- mean(d2007$p_housing_own, na.rm=T)
  
  d2011$log_pop_denc[which(is.na(d2011$log_pop_denc))] <- mean(d2011$log_pop_denc, na.rm=T)
  d2011$log_pop[which(is.na(d2011$log_pop))] <- mean(d2011$log_pop, na.rm=T)
  d2011$log_median_inc[which(is.na(d2011$log_median_inc))] <- mean(d2011$log_median_inc, na.rm=T)
  d2011$avg_home_val_log[which(is.na(d2011$avg_home_val_log))] <- mean(d2011$avg_home_val_log, na.rm=T)
  d2011$avg_home_val[which(is.na(d2011$avg_home_val))] <- mean(d2011$avg_home_val, na.rm=T)
  d2011$unemploy_rate[which(is.na(d2011$unemploy_rate))] <- mean(d2011$unemploy_rate, na.rm=T)
  d2011$p_uni_degree[which(is.na(d2011$p_uni_degree))] <- mean(d2011$p_uni_degree, na.rm=T)
  d2011$p_immigrant[which(is.na(d2011$p_immigrant))] <- mean(d2011$p_immigrant, na.rm=T)
  d2011$p_housing_own[which(is.na(d2011$p_housing_own))] <- mean(d2011$p_housing_own, na.rm=T)
  
  d2003$log_pop_denc[which(is.na(d2003$log_pop_denc))] <- mean(d2003$log_pop_denc, na.rm=T)
  d2003$log_pop[which(is.na(d2003$log_pop))] <- mean(d2003$log_pop, na.rm=T)
  d2003$log_median_inc[which(is.na(d2003$log_median_inc))] <- mean(d2003$log_median_inc, na.rm=T)
  d2003$avg_home_val_log[which(is.na(d2003$avg_home_val_log))] <- mean(d2003$avg_home_val_log, na.rm=T)
  d2003$avg_home_val[which(is.na(d2003$avg_home_val))] <- mean(d2003$avg_home_val, na.rm=T)
  d2003$unemploy_rate[which(is.na(d2003$unemploy_rate))] <- mean(d2003$unemploy_rate, na.rm=T)
  d2003$p_uni_degree[which(is.na(d2003$p_uni_degree))] <- mean(d2003$p_uni_degree, na.rm=T)
  d2003$p_immigrant[which(is.na(d2003$p_immigrant))] <- mean(d2003$p_immigrant, na.rm=T)
  d2003$p_housing_own[which(is.na(d2003$p_housing_own))] <- mean(d2003$p_housing_own, na.rm=T)
  
  # put the data back together
  dt <- rbind(d2003,d2007,d2011)
  
  #make square terms for each variable - used in entropy balancing
  dt$log_pop_sq <- (dt$log_pop)^2
  dt$log_pop_denc_sq <- (dt$log_pop_denc)^2
  dt$log_median_inc_sq <- (dt$log_median_inc)^2
  dt$avg_home_val_log_sq <- (dt$avg_home_val_log)^2
  dt$unemploy_rate_sq <- (dt$unemploy_rate)^2
  dt$p_uni_degree_sq <- (dt$p_uni_degree)^2
  dt$p_immigrant_sq <- (dt$p_immigrant)^2
  dt$p_housing_own_sq <- (dt$p_housing_own)^2
  
  #subset
  d2007 <- dt[which(dt$year==2007),]
  d2011 <- dt[which(dt$year==2011),]
  d2003 <- dt[which(dt$year==2003),]
  
  # overwrite the initial data file with data without missing values
  divisions <- dt
  rm(dt)

```

